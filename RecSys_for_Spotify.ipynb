{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSys-Bidirectional RNN with Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research problem:\n",
    "The goal of the challenge is to develop a system for the task of automatic playlist continuation. Given a\n",
    "set of playlist features, participants’ systems shall generate a list of recommended tracks that can be\n",
    "added to that playlist, thereby ‘continuing’ the playlist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "1. For generating embeddings please refer to Embeddings keras.ipynb\n",
    "2. Extracting all playlists pertaining to particular keyword please use Workout playlist extraction.ipynb\n",
    "3. Helpers function to generate batches helpers.py\n",
    "4. Basic json used for sanity testing. mpd.slice.1000-1999_100_set.json\n",
    "5. Embeddings are not uploaded due to github size restrictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import math as m\n",
    "\n",
    "# Importing LSTMs\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining MACROS and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your trained path file here.\n",
    "\n",
    "#fullpath = ['../train_set_untouched/data/mpd.slice.1000-1999.json']\n",
    "#fullpath = ['sleep_100.json']\n",
    "fullpath = ['sleep_1000.json']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the pre-processing of the Spotify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "21374\n",
      "893\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Input to seq to seq model\n",
    "X_train = []\n",
    "# 0 and 1 are reserved for EOS and PAD\n",
    "count = 2\n",
    "play_list_names = []\n",
    "\n",
    "# Dictionary to maintain the song index and track name, other features can be added later\n",
    "track_dict = {}\n",
    "\n",
    "# Dicionray to maintain count to uri mapping\n",
    "uri_dict = {}\n",
    "  \n",
    "for item in fullpath:\n",
    "    #print item\n",
    "    f = open(item)\n",
    "    file_content = f.read()\n",
    "    f.close()\n",
    "    mpd_slice = json.loads(file_content)\n",
    "\n",
    "\n",
    "    # Playlist name list\n",
    "    play_list_names += [re.sub('[^a-zA-Z0-9]+', '', mpd_slice['playlists'][idx]['name'].lower()) for idx in range(0, len(mpd_slice['playlists']))]\n",
    "    #print play_list_names\n",
    "    #print item, len(play_list_names), count\n",
    "\n",
    "count += len(set(play_list_names))\n",
    "#print count \n",
    "    \n",
    "for item in fullpath:\n",
    "    #print item\n",
    "    f = open(item)\n",
    "    file_content = f.read()\n",
    "    f.close()\n",
    "    mpd_slice = json.loads(file_content)\n",
    "\n",
    "\n",
    "    # Looping to create the X_train\n",
    "    for idx in range(0, len(mpd_slice['playlists'])):\n",
    "        lst_current = [] \n",
    "\n",
    "        lst_current.append(play_list_names.index(re.sub('[^a-zA-Z0-9]+', '', mpd_slice['playlists'][idx]['name'].lower())) + 2)    \n",
    "\n",
    "        for idy in range(0, len(mpd_slice['playlists'][idx]['tracks'])):\n",
    "            track_uri = re.sub('spotify:track:', '', mpd_slice['playlists'][idx]['tracks'][idy]['track_uri'])\n",
    "            if(track_uri not in track_dict):\n",
    "                track_dict[track_uri] = count\n",
    "                uri_dict[count] = [track_uri, mpd_slice['playlists'][idx]['tracks'][idy]['track_name']]\n",
    "                count += 1\n",
    "            lst_current.append(track_dict[track_uri])\n",
    "            #print lst_current\n",
    "            #print X_train, \"sac\"\n",
    "        X_train.append(lst_current)\n",
    "        #print \"done\", idx\n",
    "    print \"done\"\n",
    "\n",
    "    #print X_train\n",
    "    \n",
    "\n",
    "#print (X_train)\n",
    "print (count)\n",
    "print (len(play_list_names))\n",
    "print (len(set(play_list_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing some basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig = X_train\n",
    "#print (X_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split is: 714 and Test split is: 179\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.8\n",
    "X_train, X_test = X_train_orig[0:int(m.floor(train_test_split*len(X_train_orig)))],  X_train_orig[int(m.floor(train_test_split*len(X_train_orig))):len(X_train_orig)]\n",
    "print \"Train split is:\", len(X_train), \"and Test split is:\", len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the PAD, EOS, Vocab size and other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = count\n",
    "input_embedding_size = 300\n",
    "\n",
    "encoder_hidden_units = 300\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some placeholders for tensorflow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify this variable if you want to load the external embeddings\n",
    "external_load_embeddings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the embeddings\n"
     ]
    }
   ],
   "source": [
    "# Module to load external embeddings.\n",
    "\n",
    "if(external_load_embeddings == True):\n",
    "    print \"Loading the embeddings\"\n",
    "    embed_file = np.load('embedding_1000.npy')\n",
    "    print embed_file.shape\n",
    "    print vocab_size, input_embedding_size\n",
    "    init = tf.constant(embed_file, dtype=tf.float32)\n",
    "    embeddings = tf.get_variable('embeddings', trainable=False, initializer = init, dtype=tf.float32)\n",
    "else:\n",
    "    print \"Training the embeddings\"\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Lookup function to get embeddings as a continuous represemtation from one-hot inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `tf.nn.bidirectional_dynamic_rnn` as the encoder for better understanding of the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the encoder cell \n",
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the Bi-directional RNN with inputs and outputs merged\n",
    "\n",
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and backward outputs and state are concatenated and used for attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using raw_rnns for decoders as it allows to control what should output, what should be fed next, and hence allows us to include attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the decoder cell \n",
    "\n",
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unstacting the inputs from batches \n",
    "\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project the decoder will be able to predict sequences of lengths +2 additional steps. +500 did not work because of vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label mapping for backpropagation\n",
    "\n",
    "We are defining the weights and biases for the linear softmax layer to generate probability distribution for the predictions and map with the original sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token preparation for EOS and PAD tokens to denote End of sequence and Padding for smaler sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define two loop functions involving tensors to implement soft attention mechanism. Also by defining the loop functions we will be providing the previously generated decoder output to the current cell computation.\n",
    "\n",
    "\n",
    "Loop transition function is a mapping `(time, previous_cell_output, previous_cell_state, previous_loop_state) -> (elements_finished, input, cell_state, output, loop_state)`. It is called *before* RNNCell to prepare its inputs and state. Everything is a Tensor except for initial call at time=0 when everything is `None` (except `time`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop initialization function. Loop initial state is function of only `encoder_final_state` and embeddings:\n",
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop transition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define transition function such that maximum probable previously generated token is passed as next input.\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) \n",
    "\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, input, state, output, loop_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the initializer and transition functions to create a new raw_rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the layers and getting the logits for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the predictions in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using softmax function for generating the prediction probabilities. Categorical crossentrpy is used as a loss function for computing the difference between the actual and predicted probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.004,).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all the variables to check the basic model is correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "def next_feed(index):\n",
    "    batch = X_train[index*batch_size: (index+1)*batch_size]\n",
    "    #print (\"Batch \", batch)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    #print \"Encoder i/p:\", encoder_inputs_\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence[1:len(sequence)]) + [EOS] + [PAD]*2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss variable to track the loss after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the train method and tracking the time for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sachin/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Epoch', 0)\n",
      "10.595109\n",
      "10.30477\n",
      "10.296449\n",
      "10.184431\n",
      "Time taken per epoch:  68.8064701557\n",
      "('Epoch', 1)\n",
      "9.714048\n",
      "9.86598\n",
      "9.921107\n",
      "9.7864485\n",
      "Time taken per epoch:  67.9911730289\n",
      "('Epoch', 2)\n",
      "9.18689\n",
      "9.516655\n",
      "9.602545\n",
      "9.488873\n",
      "Time taken per epoch:  64.368366003\n",
      "('Epoch', 3)\n",
      "8.879628\n",
      "9.154964\n",
      "9.244562\n",
      "9.11173\n",
      "Time taken per epoch:  63.6041829586\n",
      "('Epoch', 4)\n",
      "8.625769\n",
      "10.014691\n",
      "9.189094\n",
      "9.79594\n",
      "Time taken per epoch:  63.6921460629\n",
      "('Epoch', 5)\n",
      "8.406231\n",
      "8.554599\n",
      "8.776959\n",
      "8.89195\n",
      "Time taken per epoch:  63.8741130829\n",
      "('Epoch', 6)\n",
      "7.8010907\n",
      "8.121935\n",
      "8.307964\n",
      "8.090075\n",
      "Time taken per epoch:  64.0411410332\n",
      "('Epoch', 7)\n",
      "7.44532\n",
      "7.712841\n",
      "8.060685\n",
      "7.683864\n",
      "Time taken per epoch:  64.5985150337\n",
      "('Epoch', 8)\n",
      "6.9585705\n",
      "7.3844247\n",
      "7.6310344\n",
      "7.2426257\n",
      "Time taken per epoch:  63.694589138\n",
      "('Epoch', 9)\n",
      "6.3532863\n",
      "6.9843874\n",
      "7.2370076\n",
      "6.8569217\n",
      "Time taken per epoch:  64.6257820129\n",
      "('Epoch', 10)\n",
      "5.925279\n",
      "6.5897164\n",
      "6.8851027\n",
      "6.382462\n",
      "Time taken per epoch:  64.1280350685\n",
      "('Epoch', 11)\n",
      "5.5481415\n",
      "6.2332425\n",
      "6.265205\n",
      "6.1097794\n",
      "Time taken per epoch:  64.2347278595\n",
      "('Epoch', 12)\n",
      "5.0888186\n",
      "5.782421\n",
      "5.9081044\n",
      "5.746878\n",
      "Time taken per epoch:  64.2642419338\n",
      "('Epoch', 13)\n",
      "4.666566\n",
      "5.4345226\n",
      "5.3578324\n",
      "5.547274\n",
      "Time taken per epoch:  64.2275719643\n",
      "('Epoch', 14)\n",
      "4.358631\n",
      "5.0362763\n",
      "4.9037876\n",
      "5.012026\n",
      "Time taken per epoch:  65.2506170273\n",
      "('Epoch', 15)\n",
      "3.978104\n",
      "4.6587815\n",
      "4.680494\n",
      "4.74624\n",
      "Time taken per epoch:  66.8974721432\n",
      "('Epoch', 16)\n",
      "3.7099733\n",
      "4.314043\n",
      "4.3374095\n",
      "4.478523\n",
      "Time taken per epoch:  66.8162670135\n",
      "('Epoch', 17)\n",
      "3.551838\n",
      "4.0214343\n",
      "4.0737247\n",
      "3.956275\n",
      "Time taken per epoch:  65.6204211712\n",
      "('Epoch', 18)\n",
      "3.2020597\n",
      "3.6006222\n",
      "3.7290387\n",
      "3.7918978\n",
      "Time taken per epoch:  65.4933550358\n",
      "('Epoch', 19)\n",
      "2.9895754\n",
      "3.3529334\n",
      "3.3823457\n",
      "3.4077299\n",
      "Time taken per epoch:  64.2763180733\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "import time\n",
    "\n",
    "\n",
    "#try:\n",
    "for i in range (epochs):\n",
    "    tic = time.time()\n",
    "    print (\"Epoch\", i)\n",
    "    index = 0\n",
    "    for index in range (len(X_train)/batch_size):\n",
    "        fd = next_feed(index)\n",
    "        #index = index\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        if(len(loss_track)%20 == 0):\n",
    "            print loss_track[-1]\n",
    "    print \"Time taken per epoch: \", time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0426_2158\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%m%d_%H%M\")\n",
    "print timestr\n",
    "model_name =  './1000_playlist_50_epoch_400_neuron' + timestr + '.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=1) \n",
    "#with tf.Session() as sess:\n",
    "savePath = saver.save(sess, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_to_load = 'sleep_50_epoch_400_neuron0424_1424.ckpt'\n",
    "saver = tf.train.import_meta_graph(model_name_to_load + '.meta')\n",
    "saver.restore(sess, model_name_to_load)\n",
    "# access a variable from the saved Graph, and s on:\n",
    "#someVar = sess.run('varName:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing on the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial test for 10 small batch\n",
    "# Trial test for 100 batch\n",
    "#X_test = [[2, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]]\n",
    "\n",
    "# Trial test for 2 files\n",
    "#X_test = [[2, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258]]\n",
    "          \n",
    "# Sleep test\n",
    "X_test_orig = X_test\n",
    "\n",
    "#print X_test_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the predictions\n",
    "batch = X_test\n",
    "batch_size = 1\n",
    "\n",
    "def next_feed_test(index):\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch[index*batch_size: (index+1)*batch_size])\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence[1:len(sequence)]) + [EOS] + [PAD]*2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }\n",
    "\n",
    "def gen_batch_from_sample(x_input):\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(x_input)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence[1:len(sequence)]) + [EOS] + [PAD]*2 for sequence in x_input]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }\n",
    "\n",
    "#fd = next_feed_test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sequence = []\n",
    "\n",
    "for index in range (len(X_test)/batch_size):\n",
    "    fd = next_feed_test(index)\n",
    "    \n",
    "    predict_ = sess.run(decoder_prediction, fd)\n",
    "    \n",
    "    for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "        print('  sample {}:'.format(index + 1))\n",
    "        print('    input     > {}'.format(inp))\n",
    "        print('    predicted > {}'.format(pred))\n",
    "    predicted_sequence.append(predict_.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(predicted_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to feed the predictions generated back as a input sequence and get more predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sachin debug [[  859]\n",
      " [ 9369]\n",
      " [33939]\n",
      " [13981]\n",
      " [16020]\n",
      " [16349]\n",
      " [ 5685]\n",
      " [12768]\n",
      " [  773]\n",
      " [  729]\n",
      " [  773]\n",
      " [  729]\n",
      " [  773]\n",
      " [  729]\n",
      " [  773]\n",
      " [  729]\n",
      " [  773]\n",
      " [  729]\n",
      " [  773]]\n",
      "[2, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 859, 9369, 33939, 13981, 16020, 16349, 5685, 12768, 773, 729, 773, 729, 773, 729, 773, 729, 773, 729, 773]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "prediction_matrix = []\n",
    "for index in range (len(X_test)/batch_size):\n",
    "    fd = next_feed_test(index)\n",
    "    #print fd\n",
    "    \n",
    "    predict_ = sess.run(decoder_prediction, fd)\n",
    "    print \"sachin debug\", predict_\n",
    "    \n",
    "    # trying to generate 500 predictions\n",
    "    \n",
    "    orig_test_seq =  X_test[index] + predict_.reshape(len(predict_),).tolist()\n",
    "    #print \"sac\", orig_test_seq, X_test[index][1:len(X_test[index])]\n",
    "    play_list_seq = list(range(0, len(set(play_list_names))+1))\n",
    "    test_seq = orig_test_seq\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    while((len(set(test_seq)) != 500) and (len(set(orig_test_seq)) != 500)):\n",
    "        # Removing the duplicates\n",
    "        test_seq = list(OrderedDict.fromkeys(test_seq))\n",
    "        # Removing the EOS and PAD\n",
    "        test_seq = [x for x in test_seq if x not in [0,1]]\n",
    "        \n",
    "        fd_input = X_test[index] + [x for x in test_seq if x not in X_test[index]]\n",
    "        \n",
    "        fd_test = gen_batch_from_sample([fd_input])\n",
    "        predict_ = sess.run(decoder_prediction, fd_test)\n",
    "        local_prediction = predict_.reshape(len(predict_),).tolist()\n",
    "        orig_test_seq +=  [x for x in local_prediction if x not in orig_test_seq]\n",
    "        #print \"iter\", count, test_seq, orig_test_seq\n",
    "        test_seq = orig_test_seq\n",
    "\n",
    "        count += 1\n",
    "        if(count == 100):\n",
    "            break\n",
    "    \n",
    "    local_prediction = predict_.reshape(len(predict_),).tolist()\n",
    "    orig_test_seq +=  [x for x in local_prediction if x not in orig_test_seq]\n",
    "    \n",
    "    \n",
    "    seq_list = list(OrderedDict.fromkeys(orig_test_seq))\n",
    "    \n",
    "    seq_list = [x for x in seq_list if x not in play_list_seq]\n",
    "    \n",
    "    # Change\n",
    "    seq_list = [x for x in seq_list if x not in X_test[index]]\n",
    "    prediction_matrix.append(seq_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sequence: 0\n",
      "Photograph, Love Is an Open Door, 7 Years, Wish You Were Here, I've Got a Dream - From \"Tangled\"/Soundtrack Version, You'll Be In My Heart, Does Ya Mama Know? (Dance Like That) #HEYNOW, Poor Unfortunate Souls - Broadway Cast Recording, Sorry, Where Are Ü Now (with Justin Bieber), Vroom Vroom, Applause, Come Together, Wildest Moments, Ghostbusters, When You're An Addams, Lucky, Dog Days Are Over, Dancing Through Life - From \"Wicked\" Original Broadway Cast Recording/2003, I've Never Felt So Good, Gold Angel - Savoir Adore Remix, C'Mon, Do I Wanna Know?, Friends on the Other Side - From \"The Princess and the Frog\" / Soundtrack Version, Breathe, Born For This, You Got Worked (feat. Mateo Senolia) [CASAMENA Stripped Remix] - Mixed, Ils appellent ça, Kif'n'dir, Positoovity - Broadway Cast Recording, Kiss the Girl - From \"The Little Mermaid\"/Soundtrack Version, Closer, Cheerleader, C.O.U.N.T.R.Y., It's My Life, Diss Me, Doin' it Right, Still Want You, Devil Eyes, The World Above (Reprise) - Broadway Cast Recording, Sweet Child - Broadway Cast Recording, All Creatures, You're Going Down, Green Light, Big Men in the Sky, They Are All In Love, Coffee, This Is War, Menswear, Vice Grip, A Whole New World, This Is The Last Time, Say You'll Be There, Silence in Me, Trndsttr (feat. M. Maggie) - Lucian Remix, Miracles, No More Mr. Nice Guy, Yours (Glory and Praise) [Acoustic], Good Life (with G-Eazy & Kehlani), Do It Big (feat. Bad Lucc, Sage The Gemini), Last Resort, Somebody That I Used To Know, Raging, Magic Carpet/Parting The Seas, One Jump Ahead (Reprise), Lean On (feat. MØ & DJ Snake), Hand on My Gat, 7/11, Circle Of Life - From \"The Lion King\"/Soundtrack, A Million Miles Away, Home, Part of Your World (Reprise) - From \"The Little Mermaid\"/ Soundtrack Version, Prince Ali (Sultan Reprise), On Top Of The World, Belle, Twist And Shout - Remastered 2009, Ella No Cree En El Amor, Riptide, Come On Eileen, Formidable, Hear The Sound, Ladies and Gentlemen We Are Floating in Space, I'll Make a Man Out of You - From \"Mulan\"/Soundtrack, One Step Closer - Broadway Cast Recording, Can't Sleep Love, Sunrise, Haven't Met You Yet, Ginza, Defying Gravity - From \"Wicked\" Original Broadway Cast Recording/2003, Courtesy Call, Best Light\n",
      "\n",
      "\n",
      "[14360, 13277, 3805, 15906, 13278, 773, 16026, 726, 1536, 1535, 16020, 7901, 13248, 3035, 14612, 14620, 12847, 3341, 17555, 3864, 13640, 13023, 2004, 29504, 30560, 10447, 10015, 28781, 28782, 727, 738, 2861, 16244, 7502, 11650, 9541, 1315, 14160, 1660, 722, 725, 10863, 6004, 1222, 24153, 28659, 2001, 29707, 28201, 5960, 859, 16182, 17113, 33939, 1633, 14904, 14615, 10825, 1850, 7888, 5336, 1324, 3902, 846, 857, 1534, 8835, 1538, 3911, 755, 5131, 740, 764, 7632, 800, 13144, 13433, 3037, 1094, 20403, 10856, 25127, 3908, 729, 5675, 5683, 14131, 5828, 22077, 5972, 13639]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(prediction_matrix)):\n",
    "    song_names = [uri_dict[x][1] for x in prediction_matrix[i]]\n",
    "    song_names = map(lambda x:x.encode(\"utf-8\"), song_names)\n",
    "    print \"Predicted sequence:\", i\n",
    "    print \", \".join(song_names)\n",
    "    print \"\\n\"\n",
    "    print prediction_matrix[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Precision metrics computation (R-Precision and NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## R-Precision\n",
    "def r_precision(r):\n",
    "    \"\"\"Score is precision after all relevant documents have been retrieved\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> r_precision(r)\n",
    "    0.33333333333333331\n",
    "    >>> r = [0, 1, 0]\n",
    "    >>> r_precision(r)\n",
    "    0.5\n",
    "    >>> r = [1, 0, 0]\n",
    "    >>> r_precision(r)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        R Precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    z = r.nonzero()[0]\n",
    "    if not z.size:\n",
    "        return 0.\n",
    "    return np.mean(r[:z[-1] + 1])\n",
    "\n",
    "## DCG computation\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "## NDCG computation\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-Precision and NDCG for a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Precision is 190 0.0736842105263\n",
      "NDCG metric: 0.21043817599412445\n",
      "[0, 0, 0, 0, 0, 124, 0, 175, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 174, 163, 0, 0, 0, 0, 0, 0, 0, 0, 179, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 40, 0, 0, 0, 0, 142, 0, 161, 133, 0, 97, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NDCG metric: 0.21043817599412445\n"
     ]
    }
   ],
   "source": [
    "# Computing the r-precision\n",
    "test_idx = 0\n",
    "\n",
    "## R-Precision\n",
    "print \"R-Precision is\", len(X_train[test_idx]), len(list(set(prediction_matrix[0]) & set(X_train[test_idx])))/float(len(X_train[test_idx]))\n",
    "\n",
    "\n",
    "## NDCG computation\n",
    "ndcg_arr = [(len(X_train[test_idx]) - X_train[test_idx].index(x)) if x in X_train[test_idx] else 0 for x in prediction_matrix[0]]\n",
    "print \"NDCG metric:\", ndcg_at_k(ndcg_arr, len(ndcg_arr))\n",
    "print ndcg_arr + (500-len(ndcg_arr))*[0]\n",
    "print \"NDCG metric:\", ndcg_at_k(ndcg_arr, len(ndcg_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs of loss function vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.4077 after 1600 examples (batch_size=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8FVX6P/DPuemVJCTUAKE3DS0g\nHRQEFJR1xbZY1vLDVb/W1RXFujbsvbHoqqgodldQEAtFEUjoSO+hpBASSEL6+f1xZ+6d29vcms/7\n9fKVe2fmzjwOyZOTM+c8R0gpQURE4c8Q7ACIiEgfTOhERBGCCZ2IKEIwoRMRRQgmdCKiCMGETkQU\nIZjQiYgihMuELoR4VwhRLITYotn2rBBiuxBikxDiKyFEmn/DJCIiV9xpob8HYJLVth8BnCGlzAWw\nE8B9OsdFREQeinZ1gJRyuRAix2rbEs3bPwBMc+dimZmZMicnx+VxRERkVlBQUCqlzHJ1nMuE7obr\nAHzqzoE5OTnIz8/X4ZJERM2HEOKAO8f59FBUCDELQAOAj5wcM0MIkS+EyC8pKfHlckRE5ITXCV0I\ncQ2AKQCmSycVvqSUc6SUeVLKvKwsl38xEBGRl7zqchFCTAJwL4AxUspqfUMiIiJvuDNscT6AVQB6\nCiEKhRDXA3gNQAqAH4UQG4QQb/k5TiIicsGdUS5X2Nn8jh9iISIiH3CmKBFRhGBCJyKKEGGT0Jds\nPYbiUzXBDoOIKGSFRUKvb2zCjHkFuGLOH8EOhYgoZIVFQm9ShrkfLOMISSIiR8IioavTlhxPXyIi\norBI6I1NzORERK6ERUJXu1yY1omIHAuThG786qRkDBFRsxceCZ1dLnYt31mC03WNwQ6DiEJEeCR0\ntsxt7C6uxNXvrsGsrzYHOxQiChFhkdAbmdBtnKqpBwDsKa0KciREFCrCIqGbhi0GNwwiopAWFgnd\nNMpFAjX17DMmIrInLBK6dhz6vFVuLa1HRNTshEVC13ahsz+diMi+sEjo2hb6J2sOBjESIqLQFRYJ\n/eWfdple7z9ejU2F5UGMJsTwLxYiUoRFQj95ut7i/V0LNgYpktAhhAh2CEQUYsIioacmxFi8Zxld\nIiJb4ZHQ4y3XsmbblIjIVngkdKsWOhER2QqPhB5vmdDZfczKk0RkKywS+vm5bZEQExXsMIiIQlpY\nJPT2aQnY9tgkJMcZ+9IFe9HN+OcKESnCIqGrWibHAgBO1zeaqg0SEZFRWCX0j244y/R63h+s6UJE\npBVWCT07PRFrZ40HAKzaczzI0RARhZawSugAkJUSh/ZpCchKjsP2YydZTpejXYhIEXYJHTA+B/xy\n/WFMemkFHv3fn8EOJyg49Z+IrIVlQh/UKd30ev6ag9h4qBwnquqCGBERUfBFuz4k9Pylf3t8s+GI\n6f3U139DrzYpOFFdh+FdM/HiZf2DGB0RUXCEZQt9bM8sm23bj51C0clafLX+MCprG4IQFRFRcIVl\nC10Igfn/bygOnajG3BV7sbOo0mL/GQ8vBgBcNKA9/j48B7nZLdjnTEQRLyxb6AAwrGtLXJrXAUvu\nHIOLBrS3e8xX6w9j6uu/4T8r9gY4OiKiwAvbhK714mX98fZVgxzuf3LR9gBGQ0QUHBGR0AFgYt82\n2PLoRAzpnGF3P6sTElGkc5nQhRDvCiGKhRBbNNsyhBA/CiF2KV/TnZ0jUJLjorHgxmFYdNsom32n\nahvwWf4hjHn2F+wqOhWE6IiI/MudFvp7ACZZbZsJ4CcpZXcAPynvQ0afdqn46ubhOFszGuZ4ZR3u\n+XwTDhyvxrkvLsfWIxUAgH2lVdhbUunoVCGPf3cQkcplQpdSLgdQZrV5KoD3ldfvA/iLznH5bEDH\ndPz32iH44LohAIDSylqL/TuOncIFr67E2c/9inOeX4YVu0ow44N8NDWFfopsbJJYkH8o2GEQUYjx\ntg+9tZTyKAAoX1vpF5K+WqXGAQAe/d9Wi+13LdiIzYcrTO+vemcNlvxZhLkr96L7rEVYtrMkoHF6\n4qPVB/Dx6oPBDoOIQozfH4oKIWYIIfKFEPklJYFPkj1apQAAthw+6dbxTy7ajvpGiWveXROyE5RO\nVLEWPBHZ8jahFwkh2gKA8rXY0YFSyjlSyjwpZV5Wlu0MT38zGASenZbr1WfPeHgx3l25T+eIfGfQ\nzJHidCkiUnmb0L8FcI3y+hoA3+gTjn9cPDDb68/++ztjNceCA2XImbkQ24+519L3J056JSJ73Bm2\nOB/AKgA9hRCFQojrAcwGcK4QYheAc5X3Ictg8C0D7i6uxP82HgUA/L7bvLDGobJqfLvxiKOP+Y2r\nMgY7jp3Cil2h+wyAiPzDnVEuV0gp20opY6SU2VLKd6SUx6WU46SU3ZWv1qNgQs6/p/a12ZaZHIvY\naANGdsvE+9cNQZ+2qXY/+8W6QtQ1NhnP892fKFNK9V70xm+4bf76gE9actVCn/jSclz1zprABENE\nISMsi3N544ohHXFOr1YY+fQvpm1L7xqDtMRY0/sxPbKQM3OhzWdbJsWi9JR52OOUV1bgSEWN6f3W\nIycx7a3f8f3to7H0zyLk5aRjQEf/zbUS7DknIjuaTUKPiTIgOz0R/5rUE9EGgRmju9o9bv/syTZJ\n/UR1HWobmkzvtckcAF5augs19U14e9kefLL2kOk8/uJjDxIRRahmk9BVN4/t5vKYtMQYlFfXY99T\n56PzfYvw+i97EBPlOIsu3VYEAKZk7m98KEpE9jS7hO6OpXeNQVlVncXDx/pGz/rJJ7y4DGmJsVhw\n4zAAwJbDFeialYyE2CjTMdV1DUiM9fyfQNvlEvrzWokoUCKm2qKeMpPj0KO1cULS8nvO9uocO4sq\nsWZfGf6zfC8qTtdjyqsrcdeCDab9S/8sQp+HFmP9wRMen5stdCKyhwndhY4tE336/BOLtuFUjXFm\n5x97zUMe1WGFGw+Ve3xOrr5ERPYwobvB3pBHT9QpD1RPVNejtLIWU15dgfdXHfD6fO6mc9aAJ2pe\nmNDdcNXQTrjtHPsPUzc8dC6mn9XR4WdHdc9EdV2j6X3e40sd1pWRUmKPG6V8taNcNhVWYHex/c+E\nQeFIItIRE7obhBC4a0JPu/uiowx44qIz8dk/hiHHTvfMil2lWLXnuJ1Pms+tuvjN3zHu+WXYoqkC\nCQBVtQ2oqW+0+xkAGP/CMrvnrm9ssrudiCITR7l4Ia9TOp646EycqK5DcpzxFg7OycC3t45E7iNL\nbI5/YtE2h+d65oftKDhwwqKEQOGJapzRvoXpfd+HF6N9WgJ+m3kOAPcfijayiU7UrLCF7oV3/j4Y\nPdukYGiXlhbbU+NjMLJbJgDgyYvOxPjersvEV9U12qkHIzBi9s/o/eAPpi2Hy0+b97qZ0Rs8HGpJ\nROGNCd0LcdGOb5tURoZ3zEjEg1P6eHX+hZuP4nD5aZzWdLMAwDFlhqq9dD7vjwPImbkQPymTnACg\noYldLkTNCRO6F2KjHN82NYcaBNCpZRKG5GR4fP7/aVrszy3eYXrd0NSEuoYmnKyxXeDiwa+Na3i/\n9stuzfESby/bgyvnrvY4BiIKP+xD98CH15+F7zYdcVqON1GZCRqtJH2Dj78ytQn6nws2YvU+54Ut\ntd0sDU0ST32/HQBwuq7RYpYqEUUettA9MLJ7JmZf7Hz1o6en5eLO8T2Q18lYbfHcPm10u76rZA7A\nYp3UBs0ol5d/2oXahkb8sr0YS/8swjovZqgSUWhjC11nmclxuH18d9P760bk4DFl1aNA+7yg0PS6\nqrYBT3+/A+/+Zl5Sz58VIYko8NhC9zMhBH68czTO1AxDVA3smObXa7/6s7m75mhFjUUyJ6LIw4Qe\nAN1bp6B9WoLN9pnn9caCG4chISYKb0wf6NcYlmpGvxBRZGKXS4DEx5h/d3bMSMTyf5mrOG57bBIA\ncx12ALhiSAfMXxOY+upEFBnYQg+QRGVG6SWDsvHVzcPtHvPCpf1Mr5/6ay7mXT/ErzE1NUnsOHYK\n+0urcPB4NU5U1eHn7UXoct9CVFTXo6GxCRu8qAZJRMHBFnqA3DGuO45X1uKhC/ogJT7G7jHqwhVj\nemQBMA47dMeYHllYtrPE45ju/nwjvlx32GLbqO6ZaJLA2v1l+GPvccxduQ9vXTkIk87Qb7QOEfkH\nW+gB0io1Hm9flecwmQPAoJx0dMxIxD8n9AAAxDmZwKT1xvSBXo1YsU7mABAXbRyr3tAksVyp2f6P\nDws8PjcRBR5b6CEkNT7Gom99WNeWDo8VAlh8x2jUNzYhKU6/f0ZzhUaJitO2M1JnfrEJX60/jB2P\nn6fbNYlIH2yhhzAhBJbdMxZ3Ky12i30AerROQd92tsMhfVFd1wAAqGuUdtdR/WTtIdQ2sEYMUShi\nQg9xnVomYdIZbW2226u4+MzFuRiutOpX3uvdWqhr9xtnkN42fz3Kquq8OgcRBQe7XMJAUpxtDRa1\nTK/WpYM74K8D26PwxGlkp/u2FioRhR8m9DDQtkUCnr74TPTvkI7M5FicqK5Hu7R4u8dGRxmQk5mk\neww7i05hwovL3T5eSok5y/fi0rwOSE+K1T0eIrLFLpcwcdngjujZJgUtk+PQrVUyEmNd/y5WC4Tp\nwTqZ1zU0obSyFoBxZaQGq+XuVu09jqe+344Hv9miWwxE5BwTegR79W8DcPngDn459+AnliLv8aX4\neXsRut6/CN1mfQ8A2F1ciaraBlTVGhfnKDlV65frE5EtJvQI1rZFgstyv12zvOueUYc0Xvdevmmb\nlBLjX1iGa99baxr+6E7JXyLSBxN6MzXv+iGYnNsWS+8ao9s51UWp1+wr04xnJ6JA4UPRZuCD64ag\n/HQ9Kk7XIy7KgPjYKIzqnoVR3Y0lBgoeGI9Bjy/1+TraceuFJ05b7Fu0+Shiogz4dUcxHr2wr2lF\nJ0fW7i9Du7QEu1Uqicg+JvRmYLRSG8aRlslxulynsrbB9PpZzVqoAHDzR+tMry/o1w5DuzieBQsA\nl7y1CtEGgd1Pnq9LbETNAbtcyMbkXNuJTO6Y9tbvHn+msrYBv+0utbvP3eJkRGTEhE42rh7ayavP\nHThebXf7XQs22GyTUqL4ZA3u/HQDps9djWMVNWhskqZ+eCLyHLtcyII/1hm1V9Xx4zUHMesr8xj1\nmvpGDH5iKWKjDPjj/nG6x0DUHPiU0IUQdwK4AYAEsBnAtVLKGj0Co8j18eqD+HbjEYttBiFMtWO0\nk5SklHbr1hCRLa+7XIQQ7QHcBiBPSnkGgCgAl+sVGAXWB9cNwWt/G2B6v/iO0X67lnUyB4zlgFXa\n0TLsgiFyn6996NEAEoQQ0QASAdj+pFJYGN0jC1Ny25ne92yTgi2PTrR77Jc3D8eQnAxdr69N6HWa\n8ryN0pjQpZSYu2Kv3RrtRGTkdUKXUh4G8ByAgwCOAqiQUi7RKzAKvmQHC2cM7JiOBf8Yhi9vHo57\nJvbU5VrabpU3ft1tet2k5Pbf9xzH4wu34SHWhiFyyJcul3QAUwF0BtAOQJIQ4ko7x80QQuQLIfJL\nSjxf95JC18CO6cjwQyXFt5fvNb3eWXQKS7Yew9EK46MZRy10KSWk0prfXFjhcCgkUSTzpctlPIB9\nUsoSKWU9gC8B2CxnL6WcI6XMk1LmZWU5n+BC4efSPH2KfzU56Cuf+vpvmDGvAHd/ttFm377SKuTM\nXIg1+8ow6+st6HzfIgDABa+txPS5q3WJiyic+DLK5SCAoUKIRACnAYwDkO/8IxTOrhjSER0yLKfi\nRxkEhACkJh9npcR5XGXxxz+LPI5HbYV/tf4w5q856PHniSKN1wldSrlaCPE5gHUAGgCsBzBHr8Ao\ntLx8eX9ckNsOBoPtEMLWKfE4dtLYJdK2RbxXMzy/33LUreOkNHavvP7LbtTUGzvYtSFxVAw1Zz6N\nQ5dSPgzgYZ1ioRDUPi0Bh8tPY2r/9g6PaVKa529OH4i8nAxMesn9lY1U6lqm7th65CSeW7LT9N5y\nyKN5hExDY5PLImBEkYQzRcmpRbePwkkXQwXVNvGAjunISokzDTX0lzqr0rwCwu6+rzccwbRB2QCA\n3cWn0DIpjsvhUURj84WcapEQgw4ZzhecVvO3QfluemByH7/Fs6+0Cos2Oe6eGf/8MtNr7Xj28S8s\nx+RXVvgtLqJQwIROPlOHC6otZbVV7Mr/nd3N42sdLKvG3JX7LLZpu1yKNQ9jDQLYeKgctyile49U\nsCoFRTYmdPKZ2sGiTazb/j0JI7rZ1jzv1SbF9Pr6kZ11uX51XaPd7UIAN31YgIWb7bfol2w9hsIT\n1TheWYt7PtuImnr75yEKF+xDJ5+ZW+hmCbFRMNgpqnXT2K7onJmEz/IL0SIhRpfrl1fb7+P/fc9x\np63yGfMKkJYYg/POaIPPCgoxsFM6LuzXDjuKTmFgx3RdYiMKJLbQyWc3jOoCAEiOt2wfqH3rH1w3\nBM9f0g+AsUZMbnYaHvvLGTAYBFqnWq6WdP/5vTy+vqOHtt9scF1aqLy63lR2oKFJ4vZP1uOvb/yO\nCge/JIhCGRM6+eyWs7th/+zJiIuOstiuDmc0CIGLB2Vj48MT0KtNqsUxN47uavHemwEya/aXef4h\njSgloTc1SWw4VAEAqG1k9wuFH3a5kN90b5WM3/ccR3qSsWvFXheLdf7297yggY/9iLKqOjw2ta9p\nW5QyM6mxSdo84CUKJ2yhk9/cP7k3Pr7hLPRt18LhMWoCvaBfO6y67xxTq95f1EU0Hvxmq2mb2tff\nJKVpluvmw+V+jYPIH5jQyW/ioqMwvFumW8dmJcehbYsEZCXHuT5YZ+pk0jX7ykzVHG/5aL1pf8Xp\nehyv9Kw2DVEwMKFTUJkmJSk9HO6OYdfTzqJKAMASTYEw7WzXvMd/xKDHlwY8LiJPMaFTUKldLOoI\nR3vFv/xt2U7bOv1Sk9C1S+IRhTImdAoq86QkcyJfcudo/PPcHjbH9m5rHiFz7Ygc/8bFHE5hiAmd\ngkpNnNp2eY/WKRjUyXZijwCQm218wDq6Rxas5y09ffGZusXV0CTxxMI/sePYKbv7T9bU42RNParr\nGpAzc6Fp4evikywvQMHDhE5BJWEno8NyOOO7f88DAFw9rBO+/b+RWP/guTi7Zyv8evdYi88M7+re\nA1h3/WfFPky0UwpYSoncR5Yg95ElpqXxXvxxJ37fU4ohT/6E7x2UGiDyN45Dp6BSJ/VEW/Wdq33r\nI7tl4pxerbF/9mTTPrUEbmq85bj2+BjLiU3+cO/nm/Bp/iHTezXuhqYmbDlsnJS07uAJnHdmW7/H\nQmSNCZ2C6uphOThSfho3jbWsvKhOMLJTDsZEWyvmg+uGICHWvwl9d/Epi2QOaCYlNUr2u1PQMaFT\nUCXERuHRqWfYbNeWDXBIs2t0jyy/V0sc/4LjlZiOVNSYhjoer6wzbZfKZKUYrpxEAcDvMgpJqUqh\nL+tFqbWsRzhad9sEQqkmeT+3eAcA4Mv1h03bnlm8A91nfY/aBtaGIf9jC51C0qBOGXhz+kCc3auV\nw2OsW+/BWD/06ndWm17bq0Pz4R8HAAA1dU02xcuI9MYWOoWs885s6/RBp73emFHd9R3p4srJmoaA\nXo/IGSZ0Clv2+tdfu2IgXr68v93j1QeY8TH+/7bfeqTCVAjMmW83HsFaH8v/EqmY0Clsqflcm9db\nJMZgYt82Nse2axGPn/85xuG57pnYU9fYJr+yElM0i1Jrq0gu3noM1723FgBw2/z1uOStVbpem5ov\n9qFT2FJb6NbtdOuW+9pZ45EQG2Ua8y4l8OiFffHwt+YSutIPYw61y9/VNzVhzvI9mH5WJ9w4r0D3\naxEBbKFTBBBWCTxKM9rlxztHIyslDslx0TAo3+1tWsSjp2axasA47NGffthyDE8u2o7r31/r8JgD\nx6tw2sGC10TuYAudwla0QeCiAe1xaV4Hi+3a0YvdW5sTd1x0FF6+vD+GdM5A2xbm4ZDaWaj+8pCy\noMYfe+33l0spMebZXzG2Zxbeu3aI3+OhyMSETmFLCIEXL7N9AGrdYtea2r+9P0PyiL0Svb/usC3l\nS+QudrkQBcmizcdMrznxiPTAhE6k+OKm4QG93hu/7ja9rmtostl/qKwafR76AXtKKgMZFoUxJnQi\nxaBO6Vj/4Lkuj5vav50u12uRYK4Wuaekymb/txuPoLquEZ8XFOpyPYp87EOnZk2bVAFzaV5rvdum\nYtvRkwBsh0l6SztS8tK3zWPRf9hyFFW1rrtgauobUVvfhBaJMS6PpeaBLXRqtrY/Ngmr7x/n1rFP\nXmSuCOnsoasnGh2Mff/Hh+vwz882mq+n2Vff2ISv1x+GlBJTX/sN/f69RJdYKDKwhU4Rq3+HNKf7\nPVkQY0BH85J42emOK0B6wtVkpi/sdLXMWb4Xzy7eASGAHUX2l8ej5osJnSLSugfPRaIOC17cdk43\ndM5Kstw2rjte/dn8QDMlLhqnaj0v0tVorzyjxt5SY7964YnT2FNSiXYtEnCorBoAUF5d7/H1KPIx\noVNEynDQF+6pQTkZGKPMIk2Oi0br1DjdFqtYd7DcreO+3XjEtAi1yrrXR0qJJmk5S5aaH/ahEznR\nt12q6fXmRyZg6V22Bb66tU4OZEgAgNp6y2GOH/5xAF3vX4TiUzUOPkHNARM6kQP7Z09GZnKc6b0Q\nwuaB6DvX5OHdawYjLcAjTX7eXmx6LaU0DW08fOK0afu3G4/gSPlpm88CwN6SSmwurPBvkBRwPiV0\nIUSaEOJzIcR2IcQ2IcQwvQIjCgdn92yF9KRYLLljtFvHj+/dWpfrpiaYe0u3HT2FjUpyVrtc6hub\ncNv89bhsjv3SvOc8vwwXvLYSxyrYoo8kvrbQXwbwg5SyF4B+ALb5HhJR+DAoCbRVajwuzct2efwV\nQzq4PMYd2r7y8zV11zcfrsAN7+ej+6zvAcBlwj5aYb8FT+HJ64QuhEgFMBrAOwAgpayTUrr3lIco\nAj0zrR/ap9kOaXxgcm/T6wQ7I2+8mXla12B/hMysr7Zg6bYit8/T5Ic68BQ8vrTQuwAoAfBfIcR6\nIcRcIUSSqw8RNTex0eYfsz5tU232J8Z6PtisvtG29os9wsW8VjdPQ2HCl4QeDWAggDellAMAVAGY\naX2QEGKGECJfCJFfUsLSoBTZ7LV4tSV7tckdMA6vbGzyPKvaK+ZlT4OLc7OFHll8SeiFAAqllKuV\n95/DmOAtSCnnSCnzpJR5WVn+XRWGSA+XD+6A4V1bOj1mwY3DcMf47jbbtflxVPdM7J892aJeTKxm\nDPvM83rht3vPQYOLCUb2HDpR7dZx1qdes68MVZpJUEzokcXriUVSymNCiENCiJ5Syh0AxgH4U7/Q\niIJj9sW5Lo8Z0jkDQzpn2GyXMCfI3OwWNvu1DzNT4qOREBvlcsaoPYUn3H+Y+Z/le3H9yM4orarF\npW+vshhp48UfBxTCfJ0peiuAj4QQsQD2ArjW95CIwpfa4H3rykEY37uVzX7tOHa1f7tfdhq+2XDE\n5li9PLFoG55YZB6AplaNBIwFwnYVncL6g+W4dLA+I3AoeHwatiil3KB0p+RKKf8ipTyhV2BE4Uht\na/dtl4poTffK2J7m7sbLlDVQ1dx+7YicAEVnpO1maWhswoSXluNfX2yyOKaxSaLJi78cKLg4U5RI\nR2oFxegoy9El/7k6D5sfmWA8Rkn7au+LEALPXdIPAzs6rw6pF3X9UgC4/v18018VP283D3c885HF\nGPvcrwGJh/TDhE6kIzU5WhfJiokyICXe+HBUbfhqhxROG5SNiwY4X8DaVTlgd5VX19nd/smaQ6bX\n1XWNOFjm3oNXX1TXNbgsI0zuY0In0pGamgxOFsEw5S+rQ1z1cEzs28Zm2z/GdHU/OIWjUTVNEqg4\nXY+CA4HpOT1RVYc+Dy3Ga5pSxOQbJnQiHamtTWfTedQuF+tj7LVU42MMNmPXtf4yQJ/1TQFg+a4S\n9Ht0CS5+83eL7ZNfWYFzNN0vJ2vqcf7LKzD22V98qgVTfKoWAGxKA5P3WA+dSEft0hJworre4oGo\nDSVvW7fi7bWbbx7bDZW1DZizfK/NvhYJMYjWsf65vclKn649iK1HTlpsy33EvOzd80t2oG+7VFw9\nLMdU14aChwmdSEf/vXYw/thbZrP4tJY6ysR2kQrL9+9fNwQju2XiiYXGIYcxVg9atbXa/eXeLzab\nXpdW1tr8tfBZQSE+KzAWJzv/zLYenVunpVlJgwmdSEetUuJxYT/n3SCmLnTrhG51nLpSkjp937o1\nHmUQXs0y9Vbe40uREmc/ZVR6sQQf6Y996EQBJh11uTgY7aEOM4yOMuAZzSzWsT1beTXL1BeO1k7V\nxv7MD9vR9f5FLs/FwS36Y0InCrBLlYlFAzumu3V8g1ISMSZKoL8yVj05LhrXjchB2xa25XqDQft7\n5Y1f93j0i4ZdL/phQicKsJFK0a4OGYkW27UtVm0fvNqtEm0wmCYjtUqJgxACGUmxuG2cbZGwQMvf\n7/5Qx/z9ZSg6aR4ds7Oo0h8hNUtM6EQhQh3OOKp7psVi1Grtc4vZp5qXd53bAz/e6d4SeFr2arN7\n64t1hciZuRAfrT7g8thpb63CxJeWWxQyI30woROFCLWF3qtNCrJSzItTTz+rEwDgrM7mkr7WvRSO\nhgw6WxbvvWsHexeoE7O+2uJ0v1ofpry6PuD9/80BEzpRiDCPfrFMzsO6tsT+2ZPRpkW8KelbHxNl\n9X7RbaOw8aEJuHZEZwCwuzReq9R4fQJ3orahEbuLT5kemj71vbnqo73SvXUNTVi89Zjf44pUTOhE\nIcKUrJ0c0+TgGOvaMX3apaJFYoxpJI31/kCQUmLam6sw/oXlGPf8MpyqqbeYFbqj6JTNZ15cuhM3\nzivA8p1c3cwbHIdOFCLME46c1IGB/UlJjj6iTlgNRkLvfJ956OLe0iqc+cgSdMgw/6Vw92cbbT5z\nSCkIdsJBATFyji10ohAx6Qxj8a2p/R1PTDK34m0nGTk9XgC3nO15IS93uVqyT9XY6Fu/eXl1HY5X\n1vp0jkjGhE4UIrpmJWP/7Mno7WT0iTZBa1n3oavULpooISwmMm18aIJPsVr7fc9xt46r9+JBaFVt\nA77ZcBgA0P/fP2LQ40s9PkeUamJcAAAQkUlEQVRzwS4XojDiaKifo1Eu6kiSKINlm75FouNaM/7k\n7sgWbbfTrK824+sNR9AlM9nimDHP/oIhORl49pJ+usYYzthCJwojjsoGaN9bLAItpWn/VcNybM53\nRvtUTOjT2ma7v6hj6q0Ne+onnP3cr/hhi+0IlyPlxklI1XWWZQcOHK/GZwWF+gcZxpjQicKQoy4X\ngwDmXpNn2q5toWvHtqu+u3UU5lydZ7PdFVcFyBxxlNCPVtRgX2mVaVas9n9vzf4yr67VHDGhE4WR\njKRYAMCwLpYPIQ0OfpI7KuUFrhrWyafrWpfunX3xmV6dp8HNh6Llp+txqqYer/9iXs1o8dYiJ58g\ngH3oRGGlXVoClt0z1maikKNRLulJsdg/e7JH13jtbwOQnhiLEd0ykTNzofE8ibGmFYYAIDHWu9Rh\nr9xvy6RYHK+yHKb44Ndb8Ph3f6JWs+jG4XLzGqdfrmNXiz1soROFmU4tk2xWRHK2hqmnhnZpiRHd\nMi22PXRBH93Ob63RQR3dWqsVlJI0v0TuWmAew15T3wjAuDRezsyF+G5T813SjgmdKALomdDtnWmk\nVYLXU3l1vXsHOvhfXLX3OF75aRcOlBpb8G8t26NTZOGHXS5EEUDtcrH34NNT9trLobBeqPVkKtW1\n/10LAHjhx52BDCckMaETRYAog8ALl/bDkM4ZPp+ryU4/tzaV/nL3WADAmvvH4WRNA8a/sMzp+Vqn\nxqHoZOBmdzpK/M0Bu1yIIsRfB2YjOz3R9YEuxMdGmV5nJsfh0rxsi4k+nTOTABirNXZrlWzzeWtf\n3jzC55gAoNFeeUY37C6utPtLKhKxhU5EJiv+dTZS482zSPMfGA/AOP3eW2kJ+sxKdbdsgPq75/OC\nQvyyoxgLNx3FPRN7IjM5Fo99tw2bHp6AhZuP4tb56/HFTcMxqJN7SwGGAyZ0IjKxXhZPlahptXsq\nNtqyI6B321QkxBiw7mC5R+dpcDApydrpukYUnayxqOa4/uAJLN1WDACoaWjErfPXAwCW7yyJqITO\nLhcicslZSV97lt0z1vQ62uqB6qtXDPAqBncnJe0qrsRZT/5ksa2m3vzLoE4zHFLP0UGhgC10ombk\ntb8NsLt6kV6m5LbFmB5Z6NQyybTN+pdBYmyUV8vP1bnZQrdHHasOWI5v1/6uWfpnEdqmxaNvuxZe\nXyfY2EInakam5LbDgI7+62Jon56AS/I6OD0mKS7a7oxRV+oavE/o2hoy0+euNr0uqazFfV9uRsGB\nMtzwQT4mv7LS7ufLq+tw04cFKA/xhTfYQicifHzDWTZ93d5wZzRJi4QYr1rou4srvQkJgGWrXHue\nD1YdAADMX3PQ6effXbkP3285hp5tUnDH+B5ex+FvbKETEYZ3y0Reju9j2NMSY53uH9MjCwBw2WBj\nK/7igdlun9u63osnrMsIeErtNgr14Y9M6ESkiwcm98b/G9XF9D4+xja93DauOwDg2hGdse+p85ES\n77yT4PW/DdQltorTbpYXcOBoxWkAxhWgSitr8e7KfZAOatAEE7tciEgXVw7tZNFt8/vMcTbj17XP\nR4UQLpNiy2TnLX53lXnYuq+pb8T/fbwOLZPi8PS0XCzIN1Z3bJQSd3yyASt3l2JEt0z0bJOiS3x6\n8bmFLoSIEkKsF0J8p0dARBSerIcnZiTFmsa198s2jhyxHiRoL513zTKPkLGuww7A6Zqrepi7Yi96\nPfgDlm4rxqf5h7Bw01HTvjd/3YNSZZHqA8er/BqHN/TocrkdwDYdzkNEYcxRTXbAnLithzA2WbXQ\n/3ZWR/zv1pGac9qmqFvO7up9kG54fKFlOrvl43UW77cfOwUAmDGvwLTtyrmrTbXjg8mnhC6EyAYw\nGcBcfcIholC19K4x+GTGUIf7nU0+UvO29RHaZ4xRBoEnLzoTibHRSFMWsY42CIuJSFcM6ejVCBl/\nOlJ+Git3lwY7DAC+t9BfAvAvAL49QiaikNetVTKGWi195y6ptNGtc762ga5N1K1T4gEYk7y27EBs\nlLBp1Qfb8Nk/O91fWlmLD1btD0gsXid0IcQUAMVSygIXx80QQuQLIfJLSkq8vRwRhSh3Fr8wt9CF\n1Xb7yVkdIRMbbbBI9DFRBqhzhFyNkAkm7QSkGR/k46FvtuJQWbWTT+jDlxb6CAAXCiH2A/gEwDlC\niA+tD5JSzpFS5kkp87Kysny4HBGFonf+nod1D57r9BhTQrdqoWtb27nZ5in3b1w5CP88twe6ZCZZ\nHHNh/3boojw0Pauz878WRnX33ypLKnv95vn7y9D/3z9i8dZjAIy1ZQAg2s4DXr15/StOSnkfgPsA\nQAgxFsDdUsordYqLiMJEXHQU4qKdV2NUk7JtQjd+vXJoR9wzsZdpe/u0BNyqjFlXjznvjDbIzU4D\nYCzzu7u4Eku3FTm8ZpRBYFT3TKzYFbj+7ZW7SrHh0AkAwI3zCtCrTYpp6GYg+v5D928WIoo4tl0u\nxq+52Wlo4aBuupoItZURO2Qk4sBx510Y0QaBQHe3X/nOaov36ogYIDAJXZeZolLKX6WUU/Q4FxFF\nHkddLmofurMytmrr3npdU3tj1DOTzWuqRhsMbq2oFCjeFCTzFKf+E5HfORrlYkrWTrqX1WOs87e9\nce/nn9kGo5V6MVFRAvdM7OllxPoLRB0YJnQi8jtHo1zU2uOOVkoCgPZpxn1ntLesU2497j3/gfF4\naEofXDywPQBjl0tslGWKm3f9EM+D10kgWujsQyciv3t6Wi6e+WG7aYFp1fUjO2NY15Y2yVprSOcM\nLLxtJPpYTfm3bqCr3S3qykZRBmHxF8G+p873eOUlPfGhKBFFhIEd0/HJjGE22w0G4TSZq+ytIqT2\nuxsEsPC2UabtahdNjMFgkcCDmcwB9qETETmkJvTebVMtCnZd0K8dLh/cAfee18vRR93y7LRcnz5v\nLWxGuRARBVrXVklolRKHeydZJu74mCjMvjgXGUmOS+/OGN3F4T7V5Ny2Fu//PjzHqzhV7HIhInIg\nMTYaa2aN9/hz+2dPBgDMWb7XYnvnzCTsKzWXxE2M1Tc9NjT5v+QVW+hEFPFaOmmtA8COxydhyZ2j\nnR43rncrn2IIQD5nQieiyPbxDWdh0e2jnB4TFx2FmCiDxcNV63OM6u5bLapAtNDZ5UJEEW24i2qQ\n6jqnANCmRbxX53DHoE7pPp/DFbbQiahZu+vcHrqf86axtqsqpcTbr1WjJyZ0IiKNNqnxeGByb5/O\nYT3yJlDY5UJEpPHH/eO8+ty0Qdn4vKBQ52g8wxY6ETVLfx3QHg9N6eP0mJQ4123eRy/siz/uG4co\nq5moqUFYUYktdCJqll64rL/LY9Y+YDnO/ZMZQ9HYJDF9rrHueU7LRFzQrx0ykmIx87xe+DT/kOlY\n7UQidZUlf2NCJyJyID7GciUm60Wyf73nbNPrdKsx7I1KTZk3pw/E4M4ZforQEhM6EZEfqC30UT2y\nkOxG140e2IdOROQHanVFeysr+Qtb6EREHvrw+rNwsMz5mqYJMVGormtEjCFw7WYmdCIiD43sbn/m\n6JpZ40yrM319ywgs21FisxaqPzGhExHppFWKuXRAj9Yp6NE6JaDXZx86EVGEYEInIooQTOhERBGC\nCZ2IKEIwoRMRRQgmdCKiCMGETkQUIZjQiYgihJBSuj5Kr4sJUQLggJcfzwRQqmM4emFcnmFcngvV\n2BiXZ3yJq5OU0uUq1QFN6L4QQuRLKfOCHYc1xuUZxuW5UI2NcXkmEHGxy4WIKEIwoRMRRYhwSuhz\ngh2AA4zLM4zLc6EaG+PyjN/jCps+dCIici6cWuhEROREWCR0IcQkIcQOIcRuIcTMAF+7gxDiFyHE\nNiHEViHE7cr2DCHEj0KIXcrXdGW7EEK8osS6SQgx0I+xRQkh1gshvlPedxZCrFZi+lQIEatsj1Pe\n71b25/grJuV6aUKIz4UQ25X7NixE7tedyr/hFiHEfCFEfDDumRDiXSFEsRBii2abx/dHCHGNcvwu\nIcQ1forrWeXfcZMQ4ishRJpm331KXDuEEBM123X9ebUXl2bf3UIIKYTIVN4H9X4p229V/v+3CiGe\n0Wz3//2SUob0fwCiAOwB0AVALICNAPoE8PptAQxUXqcA2AmgD4BnAMxUts8E8LTy+nwA3wMQAIYC\nWO3H2O4C8DGA75T3CwBcrrx+C8BNyuubAbylvL4cwKd+vmfvA7hBeR0LIC3Y9wtAewD7ACRo7tXf\ng3HPAIwGMBDAFs02j+4PgAwAe5Wv6crrdD/ENQFAtPL6aU1cfZSfxTgAnZWf0Sh//Lzai0vZ3gHA\nYhjntmSGyP06G8BSAHHK+1aBvF9++6HW8Zt/GIDFmvf3AbgviPF8A+BcADsAtFW2tQWwQ3n9NoAr\nNMebjtM5jmwAPwE4B8B3yjdwqeaHz3TflG/6YcrraOU44af7kwpj4hRW24N9v9oDOKT8QEcr92xi\nsO4ZgByrRODR/QFwBYC3NdstjtMrLqt9FwH4SHlt8XOo3i9//bzaiwvA5wD6AdgPc0IP6v2CsYEw\n3s5xAblf4dDlov4gqgqVbQGn/Nk9AMBqAK2llEcBQPnaSjksUPG+BOBfAJqU9y0BlEspG+xc1xST\nsr9COd4fugAoAfBfpTtorhAiCUG+X1LKwwCeA3AQwFEY70EBQuOeAZ7fn2D8XFwHY+s36HEJIS4E\ncFhKudFqV7DvVw8Ao5RuumVCiMGBjCscErq9FVYDPjRHCJEM4AsAd0gpTzo71M42XeMVQkwBUCyl\nLHDzuoG8h9Ew/hn6ppRyAIAqGLsQHAlIbEqf9FQY/9xtByAJwHlOrh0S33dwHEdA4xNCzALQAOCj\nYMclhEgEMAvAQ/Z2BysuRTSMXTpDAdwDYIEQQgQqrnBI6IUw9pWpsgEcCWQAQogYGJP5R1LKL5XN\nRUKItsr+tgCKle2BiHcEgAuFEPsBfAJjt8tLANKEEOrC39rrmmJS9rcAUKZzTKpCAIVSytXK+89h\nTPDBvF8AMB7APilliZSyHsCXAIYjNO4Z4Pn9CdjPhfIAcQqA6VLpFwhyXF1h/MW8UfkZyAawTgjR\nJshxQbnOl9JoDYx/QWcGKq5wSOhrAXRXRiPEwviA6ttAXVz57foOgG1Syhc0u74FoD4pvwbGvnV1\n+9XK0/ahACrUP6X1IqW8T0qZLaXMgfF+/CylnA7gFwDTHMSkxjpNOd4vrTkp5TEAh4QQPZVN4wD8\niSDeL8VBAEOFEInKv6kaV9DvmZ3ruXN/FgOYIIRIV/76mKBs05UQYhKAewFcKKWstor3cmEcDdQZ\nQHcAaxCAn1cp5WYpZSspZY7yM1AI48CFYwjy/QLwNYwNLAghesD4oLMUgbpfvj4UCMR/MD653gnj\n0+BZAb72SBj/BNoEYIPy3/kw9qf+BGCX8jVDOV4AeF2JdTOAPD/HNxbmUS5dlG+S3QA+g/lJe7zy\nfreyv4ufY+oPIF+5Z1/D+Cdo0O8XgEcBbAewBcA8GEccBPyeAZgPYz9+PYzJ6Hpv7g+Mfdq7lf+u\n9VNcu2Hs41W/99/SHD9LiWsHgPM023X9ebUXl9X+/TA/FA32/YoF8KHyPbYOwDmBvF+cKUpEFCHC\nocuFiIjcwIRORBQhmNCJiCIEEzoRUYRgQiciihBM6EREEYIJnYgoQjChExFFiP8Pxmd3J41h44kA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbe1872950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
